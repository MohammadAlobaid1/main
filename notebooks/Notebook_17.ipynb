{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "    <i>\n",
    "        LIN 537: Computational Lingusitics 1 <br>\n",
    "        Fall 2019 <br>\n",
    "        Alëna Aksënova\n",
    "    </i>\n",
    "</div>\n",
    "\n",
    "# Notebook 17: CYK parser\n",
    "\n",
    "In this notebook we discuss encoding of grammar using **context free** rules, or **context free grammmars (CFGs)**. If we have a yield of the applied rules of a CFG grammar, the order of the rules can be re-constructed via _parsing_ the sequence, and a **CYK parser** (Cocke, Younger and Kasami) is a parser efficiently assigning structures to sentences. Additionally, we discuss characterization of algorithms in terms of **Big O notation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal languages hierarchy: reminder\n",
    "\n",
    "Several weeks ago, we discussed the nested hierarchy of formal languages aligned with respect to their complexities: **the Chomsky hierarchy**.\n",
    "\n",
    "<img src=\"images/10_1.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier in this class, we discussed two of those classes:\n",
    "\n",
    "  * **Regular languages:** sets of strings that are generated by some regular expression or finite state automaton;\n",
    "  * **Finite languages:** languages strings of which can be listed (i.e. non-infinite languages)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Free Grammars (CFGs)\n",
    "\n",
    "You've probably seen phrase structure grammars written as a list of re-write rules:\n",
    "\n",
    "  * S $\\rightarrow$ NP VP;\n",
    "  * NP $\\rightarrow$ D N;\n",
    "  * D $\\rightarrow$ _the;_\n",
    "  * N $\\rightarrow$ _apple_...\n",
    "  \n",
    "Rules of such shape are also known as **context-free rules**. These rules are _replacement_ rules, and their shape can be one of the followings:\n",
    "  * _one-to-many_ (i.e. A $\\rightarrow$ B C, A $\\rightarrow$ B C D);\n",
    "  * _one-to-one_ (i.e. A $\\rightarrow$ B);\n",
    "  * _one-to-zero_ (i.e. A $\\rightarrow$ $\\epsilon$);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CFGs are more powerful than regular languages. For example, earlier we saw that it is not possible to get patterns of the type $a^nb^n$ using regular languages. CFGs can easily handle patterns like that.\n",
    "\n",
    "**Example.** Consider the following CFG.\n",
    "  * S $\\rightarrow$ A S B;\n",
    "  * A $\\rightarrow$ a;\n",
    "  * B $\\rightarrow$ b;\n",
    "  * S $\\rightarrow$ $\\epsilon$.\n",
    "  \n",
    "As the following tree shows, this grammar can generate $a^nb^n$.\n",
    "\n",
    "<img src=\"images/17_1.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice.** You are given the following CFG.\n",
    "\n",
    "  * S $\\rightarrow$ A S;\n",
    "  * A $\\rightarrow$ A A;\n",
    "  * A $\\rightarrow$ b c;\n",
    "  * A $\\rightarrow$ b;\n",
    "  * S $\\rightarrow$ c d;\n",
    "  * S $\\rightarrow$ d;\n",
    "  \n",
    "Assign all possible parses to a string $bcbcd$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chomsky normal form (CNF)\n",
    "\n",
    "There are two types of symbols in CFG rules: terminals and non-terminals.\n",
    "**Terminal symbols** are ones that can only appear as leaf nodes; so, for language-related grammars, those are lexical items.\n",
    "**Non-terminal symbols** cannot appear as leaf nodes; they can be viewed as part of speech, or phrasal categories.\n",
    "_No symbol can be terminal and non-terminal at the same time._\n",
    "When working with abstract alphabets, usually terminal symbols are the lowercase letters, and the non-terminal ones are uppercase.\n",
    "\n",
    "One of the frequent reasons to employ CFGs is to parse through [XML (Extensible Markup Language)](https://en.wikipedia.org/wiki/XML) files, design communication protocols, and even compile programming languages. In computer science, a frequent way of restricting the shape of CFGs is the [Backus-Naur form](https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form).\n",
    "\n",
    "In formal lingusitics, however, the standard shape of the CFG is the [Chomsky Normal Form (CNF)](https://en.wikipedia.org/wiki/Chomsky_normal_form).\n",
    "The rules below describe the CNF, where $A$, $B$ and $C$ are the non-terminal symbols and $a$ is the terminal one.\n",
    "\n",
    "  * All rules must be of one of the following types:\n",
    "    * A $\\rightarrow$ B C;\n",
    "    * A $\\rightarrow$ a;\n",
    "    * A $\\rightarrow$ $\\epsilon$, and\n",
    "  * There should be a unique starting symbol.\n",
    "  \n",
    "\n",
    "Any CFG can be represented in CNF, and there is a [conversion algorithm](https://en.wikipedia.org/wiki/Chomsky_normal_form#Converting_a_grammar_to_Chomsky_normal_form) that does it.\n",
    "\n",
    "**Practice.** Rewrite the grammar from the previous practice in CNF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CYK algorithm\n",
    "\n",
    "**CYK parsing algorithm** starts by constructing a table in which it stores intermediate parsing decisions. Importantly, CYK only operates on grammars given in CNF.\n",
    "\n",
    "\n",
    "    Given:   a sequence of the length N that needs to be parsed\n",
    "    Outputs: possible parses of that sequence\n",
    "    \n",
    "  * **Step 0.** Construct a table NxN (only the lower left corner part of the matrix will be filled).\n",
    "  * **Step 1.** FILLING ROW 1. Imagine that every column is annotated with the corresponding element of sequence underneath it (e.g., word). Put all possible labels of the words in the bottom row.\n",
    "  * **Step 2.** FILLING ROW 2. Try to combine labels from the level 1 and write down the non-terminals that correspond to the combinations.\n",
    "  * **Step 3.** FILLING ROW 3. Now, consider all $3$-grams of the sequence, for example, \"eats a fish\". It can correspond to two possible parses: either \"eats; a fish\", or \"eats a; fish\". \"eats; a fish\" corresponds to the possible tags of \"V,VP\" and \"NP\", i.e. either \"V NP\" or \"VP NP\". \"V NP\" can in fact be generated by \"VP\", so we fill \"VP\" in the corresponding table. The other option \"eats a; fish\" yields no possible parses.\n",
    "  * **Step 4.** FILLING ROW 4. Later, $4$-grams are considered, i.e. we look at possible parses of sequences \"she; eats a fish\", \"she eats; a fish\" and \"she eats a; fish\", etc. Again, fill the cell with all possible ways to construct the corresponding $4$-grams.\n",
    "  * **Step 5.** Finally, after all the rows are processed, the parse was assigned if the unique starting symbol is present in the upper left corner. If it is not there, this sequence cannot be parsed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/17_2.gif\" width=\"350\">\n",
    "<center> Source: <a href=https://en.wikipedia.org/wiki/CYK_algorithm> wikipedia </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice 1.** Now, let us add one more rule to the CFG from the animation above, and update the the CYK parse table.\n",
    "\n",
    "  * NP $\\rightarrow$ NP PP.\n",
    "  \n",
    "**Practice 2.** You are given the following grammar:\n",
    "\n",
    "  * S $\\rightarrow$ AB | BC;\n",
    "  * A $\\rightarrow$ BA | a;\n",
    "  * B $\\rightarrow$ CC | b;\n",
    "  * C $\\rightarrow$ AB | a.\n",
    "  \n",
    "Use this CFG to parse a string \"baaba\". The grammar is taken from [this channel.](https://www.youtube.com/watch?v=VTH1k-xiswM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CYK parser (`nltk` package)\n",
    "\n",
    "Chart parsing using a CYK parser is available, for example, through `nltk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import Nonterminal, nonterminals, Production, CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest is pretty straightforward. First, we run `nltk.CFG.fromstring` that forms a CFG based on its string representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    PP -> P NP\n",
    "    NP -> Det N | Det N PP | 'I'\n",
    "    VP -> V NP | VP PP\n",
    "    Det -> 'an' | 'my'\n",
    "    N -> 'elephant' | 'pajamas'\n",
    "    V -> 'shot'\n",
    "    P -> 'in'\n",
    "    \"\"\")\n",
    "\n",
    "print(groucho_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let us try to assign two parses to the sentence _I shot an elephant in my pajamas:_\n",
    "  * I shot \\[\\[an elephant\\] in my pajamas\\]\\];\n",
    "  * I shot \\[an elephant\\] \\[in my pajamas\\];.\n",
    "  \n",
    "The class of `nltk.ChartParser` is initialized based on the given grammar. We can use the parser's method `parse` in otdr to parse a sentence. Notice, that the chart parser implemented in `nltk` supports rules with more than $2$ symbols on the right-hand side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "parser = nltk.ChartParser(groucho_grammar)\n",
    "for tree in parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the parser finds both parses for the given sentence. (The example is taken from [here](https://www.nltk.org/book/ch08.html)). To explore more parsers provided by `nltk`, click [here](http://www.nltk.org/howto/parse.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big O notation\n",
    "\n",
    "If we have several algorithms that solve the same task or similar tasks, we need to be able to _compare_ these algorithms. One of the ways to do this is to **compare the speed** of those algorithms: namely, given the worst possible scenario (let's say, all input sentences are garden-path), how long will it take the algorithm to return some value depending on the size of the input. The performance of the algorithm is then _the function of the input size_. \n",
    "\n",
    "The **Big O** notation, usually denoted as  $\\mathcal{O}(\\cdot)$, expresses the worst-case complexity of a function or an algorithm.\n",
    "For example, the worst-case complexity of the CYK parser is $\\mathcal{O}(n^3\\cdot |\\mathcal{G}|)$, wher $n$ is the length of the string that needs to be parsed, and $|\\mathcal{G}|$ is the number of the rules in the grammar. The performance is measured in the _order of the number of operations that the algorithm needs to perform_.\n",
    "\n",
    "For simplicity, imagine that we are dealing with the grammar of the $n$.\n",
    "In this case, the complexity of the algorithm is $\\mathcal{O}(n^4)$. It roughly corresponds to the following code:\n",
    "\n",
    "    for a in range(n):\n",
    "        for b in range(n):\n",
    "            for c in range(n):\n",
    "                for d in range(n):\n",
    "                    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the exact number of operations, but rather the **order of that number** matters for the Big O notation.\n",
    "\n",
    "  * \\[Rule 1\\] **constants don't matter**.\n",
    "     * $\\mathcal{O}(7\\cdot n^4)$ = $\\mathcal{O}(9482\\cdot n^4)$ = $\\mathcal{O}(n^4)$.\n",
    "  * \\[Rule 2\\] **lower complexity terms don't matter**.\n",
    "     * $\\mathcal{O}(n^4 + n^3 + n^2)$ = $\\mathcal{O}(n^4)$;\n",
    "     * $\\mathcal{O}(n + n\\cdot \\textrm{log}(n))$ = $\\textrm{log}(n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the growth of functions $f(n) = n$ and $f(n) = n \\cdot \\textrm{log}(n)$ using [Desmos graphing calculator](https://www.desmos.com/calculator).\n",
    "\n",
    "<img src=\"images/17_3.png\" width=\"700\">\n",
    "\n",
    "While $f(n) = n \\cdot \\textrm{log}(n)$ starts slower than $f(n) = n$, it then \"accelerates\" and its values get larger and larger.\n",
    "It means, that for very small values of $n$ (e.g. extremely short sentences), the algorithm that works in $\\mathcal{O}(n)$ is faster, but if the inputs get longer, the $\\mathcal{O}(n \\cdot \\textrm{log}(n))$ one becomes much faster.\n",
    "\n",
    "**Question.** Which worst-case complexity is better?\n",
    "  * $\\mathcal{O}(n^2)$ or $\\mathcal{O}(n!)$;\n",
    "  * $\\mathcal{O}(n^4)$ or $\\mathcal{O}(n!)$;\n",
    "  * $\\mathcal{O}(\\sqrt{n})$ or $\\mathcal{O}(\\log{n})$?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
